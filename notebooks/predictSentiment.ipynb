{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['negative','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.getcwd()+'/../models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(file_path):\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tokenizer=load_tokenizer('../tokenizers/tokenizer.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_ngrams(text, n ):\n",
    "    n_grams = ngrams(word_tokenize(text), n)\n",
    "    return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text='finally after trying many mexican restaurants thru phoenix scottsdale found authentic mexican restaurant amazing fresh tortilla chip salsa ready waiting table sat down food incredible i ordered combo beef tamale red sauce chicken enchilada both full meat beginning end much flavor highly recommend place, first last time location weve moving since am long work week pit stop starbucks frappucinos for friends helped dunkin coolatas for half excuse husband tired human saying wrong drink name frappe instead coolata exhausted needed pick up apparently personal offense dunkin team instead saying serve coolatas server shift leader told husband go starbucks i hope franchise owner reads know customers told go across street and btw shift leader frappes mcdonalds want shamed saying wrong menu item head down'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_2=get_ngrams(long_text,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:  0.70455074\n"
     ]
    }
   ],
   "source": [
    "count_p=0\n",
    "count_n=0\n",
    "negative_scores=[]\n",
    "positive_scores=[]\n",
    "for gram in grams_2:\n",
    "    \n",
    "    to_predict=tokenizer.texts_to_matrix([gram], mode='tfidf')\n",
    "    predicted = model.predict(to_predict)[0]\n",
    "    if predicted[0]> 0.5:\n",
    "        negative_scores.append(predicted[0])\n",
    "    if predicted[1] > 0.5:\n",
    "        positive_scores.append(predicted[1])\n",
    "    if predicted[0]> 0.5:\n",
    "        count_n=count_n+1\n",
    "    count_p=count_p+1\n",
    "if count_n > count_p:\n",
    "    print('negative: ',np.mean(negative_scores))\n",
    "else:\n",
    "    print('positive: ',np.mean(positive_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
